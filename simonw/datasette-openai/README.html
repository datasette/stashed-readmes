<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h1 class="heading-element" dir="auto">datasette-openai</h1><a id="user-content-datasette-openai" class="anchor" aria-label="Permalink: datasette-openai" href="#datasette-openai"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://pypi.org/project/datasette-openai/" rel="nofollow"><img src="https://img.shields.io/pypi/v/datasette-openai.svg" alt="PyPI" style="max-width: 100%;" data-camo-src="https://camo.githubusercontent.com/6176f84ae16e7ebc3b10248d7015a340443c7c8268e3e7b05632b7e2397ae5b5/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6461746173657474652d6f70656e61692e737667"></a>
<a href="https://github.com/simonw/datasette-openai/releases"><img src="https://img.shields.io/github/v/release/simonw/datasette-openai?include_prereleases&label=changelog" alt="Changelog" style="max-width: 100%;" data-camo-src="https://camo.githubusercontent.com/2dfc04e2b76872783c5855899ee2cd0a1224f5d49bed4d422dc552f8e68286ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f73696d6f6e772f6461746173657474652d6f70656e61693f696e636c7564655f70726572656c6561736573266c6162656c3d6368616e67656c6f67"></a>
<a href="https://github.com/simonw/datasette-openai/actions?query=workflow%3ATest"><img src="https://github.com/simonw/datasette-openai/workflows/Test/badge.svg" alt="Tests" style="max-width: 100%;"></a>
<a href="https://github.com/simonw/datasette-openai/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg" alt="License" style="max-width: 100%;" data-camo-src="https://camo.githubusercontent.com/c355f200ea90fddaa407b6eaab303663a669248ea3ca7b1fcf77dbe04ff5f48c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322e302d626c75652e737667"></a></p>
<p dir="auto">SQL functions for calling OpenAI APIs</p>
<p dir="auto">See <a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/" rel="nofollow">Semantic search answers: Q&A against documentation with GPT3 + OpenAI embeddings</a> for background on this project.</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Installation</h2><a id="user-content-installation" class="anchor" aria-label="Permalink: Installation" href="#installation"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Install this plugin in the same environment as Datasette.</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="datasette install datasette-openai"><pre class="notranslate"><code>datasette install datasette-openai
</code></pre></div>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto"><g-emoji class="g-emoji" alias="warning">⚠️</g-emoji> Warning <g-emoji class="g-emoji" alias="warning">⚠️</g-emoji></h2><a id="user-content-️-warning-️" class="anchor" aria-label="Permalink: ⚠️ Warning ⚠️" href="#️-warning-️"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This plugin allows you to call a commercial, priced API using SQL queries.</p>
<p dir="auto">Use this with care! You could accidentally spend a lot of money.</p>
<p dir="auto">For example, the following query:</p>
<div class="highlight highlight-source-sql notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="select
  openai_davinci(
    'Summarize this text: ' || content, 200, 1, :api_key
) as summary
from documents"><pre><span class="pl-k">select</span>
  openai_davinci(
    <span class="pl-s"><span class="pl-pds">'</span>Summarize this text: <span class="pl-pds">'</span></span> <span class="pl-k">||</span> content, <span class="pl-c1">200</span>, <span class="pl-c1">1</span>, :api_key
) <span class="pl-k">as</span> summary
<span class="pl-k">from</span> documents</pre></div>
<p dir="auto">Would execute one paid API call for every item in the <code>documents</code> database. This could become very expensive.</p>
<p dir="auto">Be sure to familiarize yourself with <a href="https://openai.com/api/pricing/" rel="nofollow">OpenAI pricing</a>. You will need to obtain an <a href="https://beta.openai.com/account/api-keys" rel="nofollow">API key</a>.</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Usage</h2><a id="user-content-usage" class="anchor" aria-label="Permalink: Usage" href="#usage"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This extension provides three new SQL functions:</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_davinci(prompt, max_tokens, temperature, api_key)</h3><a id="user-content-openai_davinciprompt-max_tokens-temperature-api_key" class="anchor" aria-label="Permalink: openai_davinci(prompt, max_tokens, temperature, api_key)" href="#openai_davinciprompt-max_tokens-temperature-api_key"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This function runs a <code>text-davinci-003</code> completion against the provided prompt, with the specified values for max tokens and temperature.</p>
<p dir="auto">Da Vinci is currently 2 cents per thousand tokens.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_embedding(text, api_key)</h3><a id="user-content-openai_embeddingtext-api_key" class="anchor" aria-label="Permalink: openai_embedding(text, api_key)" href="#openai_embeddingtext-api_key"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This calls the OpenAI embedding endpoint and returns a binary object representing the floating point embedding for the provided text.</p>
<div class="highlight highlight-source-sql notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="select openai_embedding(:query, :api_key)"><pre><span class="pl-k">select</span> openai_embedding(:query, :api_key)</pre></div>
<p dir="auto">An embedding is an array of 1536 floating point values. The returned value from this is a <code>blob</code> encoding of those values.</p>
<p dir="auto">It's mainly useful for using with the <code>openai_embedding_similarity()</code> function.</p>
<p dir="auto">The embedding API is very inexpensive: at time of writing, $0.0004 cents per thousand tokens, where a token is more-or-less a single word.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_embedding_similarity(a, b)</h3><a id="user-content-openai_embedding_similaritya-b" class="anchor" aria-label="Permalink: openai_embedding_similarity(a, b)" href="#openai_embedding_similaritya-b"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This function does not make any API calls. It takes two embedding blobs and returns the cosine similarity between the two.</p>
<p dir="auto">This function is particularly useful if you have stored embeddings of documents in a database table, and you want to find the most similar documents to a query or to another document.</p>
<p dir="auto">A simple search query could look like this:</p>
<div class="highlight highlight-source-sql notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="with query as (
  select
    openai_embedding(:query, :token) as q
)
select
  id,
  title,
  openai_embedding_similarity(query.q, embedding) as score
from
  content, query
order by
  score desc
limit 10"><pre>with query <span class="pl-k">as</span> (
  <span class="pl-k">select</span>
    openai_embedding(:query, :token) <span class="pl-k">as</span> q
)
<span class="pl-k">select</span>
  id,
  title,
  openai_embedding_similarity(<span class="pl-c1">query</span>.<span class="pl-c1">q</span>, embedding) <span class="pl-k">as</span> score
<span class="pl-k">from</span>
  content, query
<span class="pl-k">order by</span>
  score <span class="pl-k">desc</span>
<span class="pl-k">limit</span> <span class="pl-c1">10</span></pre></div>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_build_prompt(text, prefix, suffix, completion_tokens, token_limit=4000)</h3><a id="user-content-openai_build_prompttext-prefix-suffix-completion_tokens-token_limit4000" class="anchor" aria-label="Permalink: openai_build_prompt(text, prefix, suffix, completion_tokens, token_limit=4000)" href="#openai_build_prompttext-prefix-suffix-completion_tokens-token_limit4000"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This aggregate function helps build a prompt from a number of inputs in a way that fits the GPT-3 prompt size limit.</p>
<p dir="auto">It takes the following argument:</p>
<ul dir="auto">
<li><code>text</code> - this is the column that is being aggregated, so the function expects to have multiple values for this. All other arguments will only be read the first time they are passed, so should be consistent across all calls to the function.</li>
<li><code>prefix</code> - text to use for the prefix of the prompt</li>
<li><code>suffix</code> - text to use for the suffix of the prompt</li>
<li><code>completion_tokens</code> - the number of tokens to reserve for the prompt response - this will be subtracted from the token limit</li>
<li><code>token_limit</code> - this value is optional (there are 4-argument and 5-argument versions of the function registered). It defaults to the GPT-3 Da Vinci size limit of 4,000 tokens but can be changed if the model the prompt is being used with has a different size limit.</li>
</ul>
<p dir="auto">Here's an example usage of this function, adapted from <a href="https://simonwillison.net/2023/Jan/13/semantic-search-answers/" rel="nofollow">this article</a>:</p>
<div class="highlight highlight-source-sql notranslate position-relative overflow-auto" dir="auto" data-snippet-clipboard-copy-content="with top_n as (
  select body from blog_entry order by id desc limit 3
)
select openai_build_prompt(body, 'Context:
------------
', '
------------
Given the above context, answer the following question: ' || :question,
  500,
  2000
  ) from top_n"><pre>with top_n <span class="pl-k">as</span> (
  <span class="pl-k">select</span> body <span class="pl-k">from</span> blog_entry <span class="pl-k">order by</span> id <span class="pl-k">desc</span> <span class="pl-k">limit</span> <span class="pl-c1">3</span>
)
<span class="pl-k">select</span> openai_build_prompt(body, <span class="pl-s"><span class="pl-pds">'</span>Context:</span>
<span class="pl-s">------------</span>
<span class="pl-s"><span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span></span>
<span class="pl-s">------------</span>
<span class="pl-s">Given the above context, answer the following question: <span class="pl-pds">'</span></span> <span class="pl-k">||</span> :question,
  <span class="pl-c1">500</span>,
  <span class="pl-c1">2000</span>
  ) <span class="pl-k">from</span> top_n</pre></div>
<p dir="auto"><a href="https://datasette.simonwillison.net/simonwillisonblog?sql=with+top_n+as+%28%0D%0A++select+body+from+blog_entry+order+by+id+desc+limit+5%0D%0A%29%0D%0Aselect+openai_build_prompt%28body%2C+%27Context%3A%0D%0A------------%0D%0A%27%2C+%27%0D%0A------------%0D%0AGiven+the+above+context%2C+answer+the+following+question%3A+%27+%7C%7C+%3Aquestion%2C%0D%0A++500%2C%0D%0A++2000%0D%0A++%29+from+top_n&question=Examples+of+a+language+model%3F" rel="nofollow">Try that here</a>.</p>
<p dir="auto">This query first retrieves the three most recent blog entries, then constructs a prompt that with the provided prefix and suffix designed to fit 1500 tokens (2000 total, minus 500 reserved for the response).</p>
<p dir="auto">The output looks something like this (truncated for space):</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="Context:
------------
< p > If you 've spent any time with GPT - 3 or ChatGPT , you 've likely thought about how ...
I release Datasette 0 . 64 this morning . This release is mainly a response to the realization that it 's not safe to run Datasette with the SpatiaLite extension loaded if that Datasette instance is configured to enable arbitrary SQL queries from untrusted users ...
In lieu of my regular weeknotes ( I took two weeks off for the holidays ) here 's a look back at 2022 , mainly in terms of projects and things I 've written about ...
------------
Given the above context, answer the following question: Examples of a language model?"><pre class="notranslate"><code>Context:
------------
< p > If you 've spent any time with GPT - 3 or ChatGPT , you 've likely thought about how ...
I release Datasette 0 . 64 this morning . This release is mainly a response to the realization that it 's not safe to run Datasette with the SpatiaLite extension loaded if that Datasette instance is configured to enable arbitrary SQL queries from untrusted users ...
In lieu of my regular weeknotes ( I took two weeks off for the holidays ) here 's a look back at 2022 , mainly in terms of projects and things I 've written about ...
------------
Given the above context, answer the following question: Examples of a language model?
</code></pre></div>
<p dir="auto">The body of each entry has been truncated to the number of tokens that will allow examples from all three entries to be included in the generated prompt.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_strip_tags(text)</h3><a id="user-content-openai_strip_tagstext" class="anchor" aria-label="Permalink: openai_strip_tags(text)" href="#openai_strip_tagstext"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Sometimes it can be useful to strip HTML tags from text in order to reduce the number of tokens used. This function does a very simple version of tag stripping - just removing anything that matches <code><...></code>.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_tokenize(text)</h3><a id="user-content-openai_tokenizetext" class="anchor" aria-label="Permalink: openai_tokenize(text)" href="#openai_tokenizetext"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Returns a JSON array of tokens for the provided text.</p>
<p dir="auto">This uses a regular expression <a href="https://github.com/openai/gpt-2/blob/a74da5d99abaaba920de8131d64da2862a8f213b/src/encoder.py#L53">extracted from OpenAI's GPT-2</a>.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">openai_count_tokens(text)</h3><a id="user-content-openai_count_tokenstext" class="anchor" aria-label="Permalink: openai_count_tokens(text)" href="#openai_count_tokenstext"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Returns a count of the number of tokens in the provided text.</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Development</h2><a id="user-content-development" class="anchor" aria-label="Permalink: Development" href="#development"><svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To set up this plugin locally, first checkout the code. Then create a new virtual environment:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="cd datasette-openai
python3 -m venv venv
source venv/bin/activate"><pre class="notranslate"><code>cd datasette-openai
python3 -m venv venv
source venv/bin/activate
</code></pre></div>
<p dir="auto">Now install the dependencies and test dependencies:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pip install -e '.[test]'"><pre class="notranslate"><code>pip install -e '.[test]'
</code></pre></div>
<p dir="auto">To run the tests:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto" data-snippet-clipboard-copy-content="pytest"><pre class="notranslate"><code>pytest
</code></pre></div>
</article></div>